@article{https://doi.org/10.1002/jrsm.1448,
author = {Samartsidis, Pantelis and Montagna, Silvia and Laird, Angela R. and Fox, Peter T. and Johnson, Timothy D. and Nichols, Thomas E.},
title = {Estimating the prevalence of missing experiments in a neuroimaging meta-analysis},
journal = {Research Synthesis Methods},
volume = {11},
number = {6},
pages = {866-883},
keywords = {meta-analysis, publication-bias, neuroimaging, zero-truncated modeling},
doi = {https://doi.org/10.1002/jrsm.1448},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1448},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jrsm.1448},
abstract = {Coordinate-based meta-analyses (CBMA) allow researchers to combine the results from multiple functional magnetic resonance imaging experiments with the goal of obtaining results that are more likely to generalize. However, the interpretation of CBMA findings can be impaired by the file drawer problem, a type of publication bias that refers to experiments that are carried out but are not published. Using foci per contrast count data from the BrainMap database, we propose a zero-truncated modeling approach that allows us to estimate the prevalence of nonsignificant experiments. We validate our method with simulations and real coordinate data generated from the Human Connectome Project. Application of our method to the data from BrainMap provides evidence for the existence of a file drawer effect, with the rate of missing experiments estimated as at least 6 per 100 reported. The R code that we used is available at https://osf.io/ayhfv/.},
year = {2020}
}